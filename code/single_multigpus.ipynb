{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单机多卡\n",
    "镜像：`fusimeng/ai.base:v2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import argparse\r\n",
      "import torch\r\n",
      "import torch.nn as nn\r\n",
      "import torch.optim as optim\r\n",
      "import torch.nn.functional as F\r\n",
      "from torchvision import  datasets\r\n",
      "from torchvision import transforms\r\n",
      "from torch.autograd import Variable\r\n",
      "import torch.utils.data.distributed\r\n",
      "\r\n",
      "import math\r\n",
      "import time\r\n",
      "\r\n",
      "import os\r\n",
      "\r\n",
      "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0, 1, 2, 3, 4, 5 ,6,7\"\r\n",
      "# -------------------- Parse CLI arguments  --------------------\r\n",
      "parser = argparse.ArgumentParser(description='Pytorch MNIST Example')\r\n",
      "parser.add_argument('--batch_size', type=int, default=200,\r\n",
      "                    help='batch size for training and testing (default: 100)')\r\n",
      "parser.add_argument('--test_batch_size', type=int, default=200,\r\n",
      "                    help='batch size for training and testing (default: 100)')\r\n",
      "parser.add_argument('--epochs', type=int, default=25,\r\n",
      "                    help='number of epochs to train (default: 10)')\r\n",
      "parser.add_argument('--lr', type=float, default=0.1,\r\n",
      "                    help='learning rate (default: 0.1)')\r\n",
      "parser.add_argument('--momentum', type=float, default=0.8,\r\n",
      "                    help='SGD momentum (default: 0.9)')\r\n",
      "# parser.add_argument('--cuda', action='store_true', default=False,\r\n",
      "#                     help='Train on GPU with CUDA')\r\n",
      "parser.add_argument('--gpunum', type=int, default=1,\r\n",
      "                    help='number of epochs to train (default: 10)')\r\n",
      "parser.add_argument('--log_interval', type=int, default=100, metavar='N',\r\n",
      "                    help='how many batches to wait before logging training status')\r\n",
      "opt = parser.parse_args()\r\n",
      "lr = opt.lr\r\n",
      "batch_size = opt.batch_size\r\n",
      "epochs = opt.epochs\r\n",
      "test_batch_size= opt.test_batch_size\r\n",
      "momentum= opt.momentum\r\n",
      "log_interval=opt.log_interval\r\n",
      "gpulist = list(range(opt.gpunum))\r\n",
      "print(\"running on:\",gpulist)\r\n",
      "# lr = 0.001\r\n",
      "# batch_size = 100\r\n",
      "# epochs = 10\r\n",
      "# test_batch_size=100\r\n",
      "# momentum=0.5\r\n",
      "# log_interval=100\r\n",
      "#������������������������\r\n",
      "transform_list = [\r\n",
      "                transforms.Resize(40),\r\n",
      "                transforms.RandomHorizontalFlip(),\r\n",
      "                transforms.RandomCrop(32),\r\n",
      "                transforms.ToTensor()\r\n",
      "                ]\r\n",
      "transform = transforms.Compose(transform_list)\r\n",
      "\r\n",
      "\r\n",
      "torch.manual_seed(2018)\r\n",
      "\r\n",
      "# Horovod: pin GPU to local rank.\r\n",
      "# torch.cuda.set_device(hvd.local_rank())\r\n",
      "torch.cuda.manual_seed(2018)\r\n",
      "\r\n",
      "kwargs = {'num_workers': 4, 'pin_memory': True}\r\n",
      "\r\n",
      "train_dataset = \\\r\n",
      "    datasets.MNIST('./mnist', train=True, download=True,\r\n",
      "                   transform=transforms.Compose([\r\n",
      "                       transforms.ToTensor(),\r\n",
      "                       transforms.Normalize((0.1307,), (0.3081,))\r\n",
      "                   ]))\r\n",
      "\r\n",
      "\r\n",
      "train_loader = torch.utils.data.DataLoader(\r\n",
      "    train_dataset, batch_size=batch_size, **kwargs)\r\n",
      "\r\n",
      "\r\n",
      "test_dataset = \\\r\n",
      "    datasets.MNIST('./mnist', train=False, transform=transforms.Compose([\r\n",
      "        transforms.ToTensor(),\r\n",
      "        transforms.Normalize((0.1307,), (0.3081,))\r\n",
      "    ]))\r\n",
      "\r\n",
      "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size,\r\n",
      "                                        **kwargs)\r\n",
      "\r\n",
      "def conv3x3(in_planes, out_planes, stride=1):\r\n",
      "    \"\"\"3x3 convolution with padding\"\"\"\r\n",
      "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\r\n",
      "                     padding=1, bias=False)\r\n",
      "\r\n",
      "\r\n",
      "# Residual Block\r\n",
      "class ResidualBlock(nn.Module):\r\n",
      "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\r\n",
      "        super(ResidualBlock, self).__init__()\r\n",
      "        self.conv1 = conv3x3(in_channels, out_channels, stride)\r\n",
      "        self.bn1 = nn.BatchNorm2d(out_channels)\r\n",
      "        self.relu = nn.ReLU(inplace=True)\r\n",
      "        self.conv2 = conv3x3(out_channels, out_channels)\r\n",
      "        self.bn2 = nn.BatchNorm2d(out_channels)\r\n",
      "        self.downsample = downsample\r\n",
      "\r\n",
      "    def forward(self, x):\r\n",
      "        residual = x\r\n",
      "        out = self.conv1(x)\r\n",
      "        out = self.bn1(out)\r\n",
      "        out = self.relu(out)\r\n",
      "        out = self.conv2(out)\r\n",
      "        out = self.bn2(out)\r\n",
      "        if self.downsample:\r\n",
      "            residual = self.downsample(x)\r\n",
      "        out += residual\r\n",
      "        out = self.relu(out)\r\n",
      "        return out\r\n",
      "\r\n",
      "\r\n",
      "# ResNet Module\r\n",
      "class ResNet(nn.Module):\r\n",
      "    def __init__(self, block, layers, num_classes=10):\r\n",
      "        super(ResNet, self).__init__()\r\n",
      "        self.in_channels = 16\r\n",
      "        self.conv = conv3x3(1, 16)\r\n",
      "        self.bn = nn.BatchNorm2d(16)\r\n",
      "        self.relu = nn.ReLU(inplace=True)\r\n",
      "\r\n",
      "        self.layer1 = self.make_layer(block, 16, layers[0])\r\n",
      "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\r\n",
      "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\r\n",
      "        self.layer4 = self.make_layer(block,128,layers[3])\r\n",
      "        self.avg_pool = nn.AvgPool2d(7)\r\n",
      "        self.fc = nn.Linear(128, num_classes)\r\n",
      "\r\n",
      "    def make_layer(self, block, out_channels, blocks, stride=1):\r\n",
      "        downsample = None\r\n",
      "        if (stride != 1) or (self.in_channels != out_channels):\r\n",
      "            downsample = nn.Sequential(\r\n",
      "                conv3x3(self.in_channels, out_channels, stride=stride),\r\n",
      "                nn.BatchNorm2d(out_channels))\r\n",
      "        layers = []\r\n",
      "        layers.append(block(self.in_channels, out_channels, stride, downsample))\r\n",
      "        self.in_channels = out_channels\r\n",
      "        for i in range(1, blocks):\r\n",
      "            layers.append(block(out_channels, out_channels))\r\n",
      "        return nn.Sequential(*layers)\r\n",
      "\r\n",
      "    def forward(self, x):\r\n",
      "        global  COUNTER\r\n",
      "        out = self.conv(x)\r\n",
      "        out = self.bn(out)\r\n",
      "        out = self.relu(out)\r\n",
      "        out = self.layer1(out)\r\n",
      "        out = self.layer2(out)\r\n",
      "        out = self.layer3(out)\r\n",
      "        out = self.layer4(out)\r\n",
      "        #print(\"###############\",out.size())\r\n",
      "        out = self.avg_pool(out)\r\n",
      "        out = out.view(out.size(0), -1)\r\n",
      "        out = self.fc(out)\r\n",
      "        return out\r\n",
      "\r\n",
      "\r\n",
      "# model = ResNet(ResidualBlock, [2, 2, 2, 2])#.cuda()\r\n",
      "model = torch.nn.DataParallel(ResNet(ResidualBlock, [2, 2, 2, 2]),device_ids=gpulist).cuda()\r\n",
      "\r\n",
      "# Horovod: scale learning rate by the number of GPUs.\r\n",
      "optimizer = optim.SGD(model.parameters(), lr=lr,\r\n",
      "                      momentum=momentum)\r\n",
      "\r\n",
      "\r\n",
      "criterion = nn.CrossEntropyLoss()\r\n",
      "\r\n",
      "def train(epoch):\r\n",
      "    model.train()\r\n",
      "    for batch_idx, (data, target) in enumerate(train_loader):\r\n",
      "        data, target = data.cuda(), target.cuda()\r\n",
      "        data, target = Variable(data), Variable(target)\r\n",
      "        optimizer.zero_grad()\r\n",
      "        output = model(data)\r\n",
      "        #loss = F.nll_loss(output, target)\r\n",
      "        loss=criterion(output,target)\r\n",
      "        loss.backward()\r\n",
      "        optimizer.step()\r\n",
      "        if batch_idx % log_interval == 0:\r\n",
      "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\r\n",
      "                epoch, batch_idx * len(data), 0,\r\n",
      "                100. * batch_idx / len(train_loader), loss.item()))\r\n",
      "\r\n",
      "for epoch in range(1, epochs + 1):\r\n",
      "    start = time.time()\r\n",
      "    train(epoch)\r\n",
      "    train_time = time.time() - start\r\n",
      "    print('epoch %d, training time: %.1f sec' % (epoch + 1, train_time))\r\n",
      "    #������������\r\n",
      "    # model.load_state_dict(torch.load('param_model.pkl'))\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! cat main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：https://blog.csdn.net/u010557442/article/details/79431520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 19 08:48:55 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 410.93       Driver Version: 410.93       CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 25%   44C    P0    53W / 250W |      0MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 24%   42C    P0    53W / 250W |      0MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on: [0, 1]\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "100.1%Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "113.5%Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "100.4%Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "180.4%Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n",
      "Train Epoch: 1 [0/0 (0%)]\tLoss: 2.325975\n",
      "Train Epoch: 1 [20000/0 (33%)]\tLoss: 0.096506\n",
      "Train Epoch: 1 [40000/0 (67%)]\tLoss: 0.069387\n",
      "epoch 2, training time: 12.8 sec\n",
      "Train Epoch: 2 [0/0 (0%)]\tLoss: 0.065229\n",
      "Train Epoch: 2 [20000/0 (33%)]\tLoss: 0.051459\n",
      "Train Epoch: 2 [40000/0 (67%)]\tLoss: 0.061293\n",
      "epoch 3, training time: 10.0 sec\n"
     ]
    }
   ],
   "source": [
    "!python main.py --epochs 2 --gpunum 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
