# Loss functions
* loss functions
    * L1Loss
    * MSELoss
    * CrossEntropyLoss
    * CTCLoss
    * NLLLoss
    * PoissonNLLLoss
    * KLDivLoss
    * BCELoss
    * BCEWithLogitsLoss
    * MarginRankingLoss
    * HingeEmbeddingLoss
    * MultiLabelMarginLoss
    * SmoothL1Loss
    * SoftMarginLoss
    * MultiLabelSoftMarginLoss
    * CosineEmbeddingLoss
    * MultiMarginLoss
    * TripletMarginLoss

æŸå¤±å‡½æ•°é€šè¿‡torch.nnåŒ…å®ç°  
### åŸºæœ¬ç”¨æ³•
* criterion = LossCriterion() #æ„é€ å‡½æ•°æœ‰è‡ªå·±çš„å‚æ•°
* loss = criterion(x, y) #è°ƒç”¨æ ‡å‡†æ—¶ä¹Ÿæœ‰å‚æ•°
## ä¸€ã€L1Loss
`class torch.nn.L1Loss(size_average=None, reduce=None, reduction='mean')`     
* åŠŸèƒ½ï¼š  
è®¡ç®—outputå’Œtargetä¹‹å·®çš„ç»å¯¹å€¼ï¼Œå¯é€‰è¿”å›åŒç»´åº¦çš„tensoræˆ–è€…æ˜¯ä¸€ä¸ªæ ‡é‡ã€‚
* è®¡ç®—å…¬å¼ï¼š   
![](../../imgs/api/02.png)   
* å‚æ•°ï¼š
    * reduce(bool)- è¿”å›å€¼æ˜¯å¦ä¸ºæ ‡é‡ï¼Œé»˜è®¤ä¸ºTrue
    * size_average(bool)- å½“reduce=Trueæ—¶æœ‰æ•ˆã€‚ä¸ºTrueæ—¶ï¼Œè¿”å›çš„lossä¸ºå¹³å‡å€¼ï¼›ä¸ºFalseæ—¶ï¼Œè¿”å›çš„å„æ ·æœ¬çš„lossä¹‹å’Œã€‚
* å®ä¾‹ï¼š
[ğŸ”—](https://github.com/fusimeng/PyTorch_Tutorial/blob/master/Code/3_optimizer/3_1_lossFunction/1_L1Loss.py)

## äºŒã€MSELoss
`class torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')`     
* åŠŸèƒ½ï¼š   
è®¡ç®—outputå’Œtargetä¹‹å·®çš„å¹³æ–¹ï¼Œå¯é€‰è¿”å›åŒç»´åº¦çš„tensoræˆ–è€…æ˜¯ä¸€ä¸ªæ ‡é‡ã€‚
* è®¡ç®—å…¬å¼ï¼š  
![](../../imgs/api/03.png)   
* å‚æ•°ï¼š   
    * reduce(bool)- è¿”å›å€¼æ˜¯å¦ä¸ºæ ‡é‡ï¼Œé»˜è®¤ä¸ºTrue
    * size_average(bool)- å½“reduce=Trueæ—¶æœ‰æ•ˆã€‚ä¸ºTrueæ—¶ï¼Œè¿”å›çš„lossä¸ºå¹³å‡å€¼ï¼›ä¸ºFalseæ—¶ï¼Œè¿”å›çš„å„æ ·æœ¬çš„lossä¹‹å’Œã€‚
* å®ä¾‹ï¼š   
[link](https://github.com/TingsongYu/PyTorch_Tutorial/blob/master/Code/3_optimizer/3_1_lossFunction/2_MSELoss.py)   

## ä¸‰ã€CrossEntropyLoss
[æå¤§ä¼¼ç„¶ä¼°è®¡](mle.md)   
[äº¤å‰ç†µæŸå¤±å‡½æ•°](crossentropy.md)   

`class torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')`    
* åŠŸèƒ½ï¼š  
å°†è¾“å…¥ç»è¿‡softmaxæ¿€æ´»å‡½æ•°ä¹‹åï¼Œå†è®¡ç®—å…¶ä¸targetçš„äº¤å‰ç†µæŸå¤±ã€‚å³è¯¥æ–¹æ³•å°†nn.LogSoftmax()å’Œ nn.NLLLoss()è¿›è¡Œäº†ç»“åˆã€‚ä¸¥æ ¼æ„ä¹‰ä¸Šçš„äº¤å‰ç†µæŸå¤±å‡½æ•°åº”è¯¥æ˜¯nn.NLLLoss()ã€‚

* è¡¥å……ï¼šå°è°ˆäº¤å‰ç†µæŸå¤±å‡½æ•°   
äº¤å‰ç†µæŸå¤±(cross-entropy Loss) åˆç§°ä¸ºå¯¹æ•°ä¼¼ç„¶æŸå¤±(Log-likelihood Loss)ã€å¯¹æ•°æŸå¤±ï¼›äºŒåˆ†ç±»æ—¶è¿˜å¯ç§°ä¹‹ä¸ºé€»è¾‘æ–¯è°›å›å½’æŸå¤±(Logistic Loss)ã€‚äº¤å‰ç†µæŸå¤±å‡½æ•°è¡¨è¾¾å¼ä¸º L = - sigama(y_i * log(x_i))ã€‚pytrochè¿™é‡Œä¸æ˜¯ä¸¥æ ¼æ„ä¹‰ä¸Šçš„äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œè€Œæ˜¯å…ˆå°†inputç»è¿‡softmaxæ¿€æ´»å‡½æ•°ï¼Œå°†å‘é‡â€œå½’ä¸€åŒ–â€æˆæ¦‚ç‡å½¢å¼ï¼Œç„¶åå†ä¸targetè®¡ç®—ä¸¥æ ¼æ„ä¹‰ä¸Šäº¤å‰ç†µæŸå¤±ã€‚   
åœ¨å¤šåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œç»å¸¸é‡‡ç”¨softmaxæ¿€æ´»å‡½æ•°+äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œå› ä¸ºäº¤å‰ç†µæè¿°äº†ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„å·®å¼‚ï¼Œç„¶è€Œç¥ç»ç½‘ç»œè¾“å‡ºçš„æ˜¯å‘é‡ï¼Œå¹¶ä¸æ˜¯æ¦‚ç‡åˆ†å¸ƒçš„å½¢å¼ã€‚æ‰€ä»¥éœ€è¦softmaxæ¿€æ´»å‡½æ•°å°†ä¸€ä¸ªå‘é‡è¿›è¡Œâ€œå½’ä¸€åŒ–â€æˆæ¦‚ç‡åˆ†å¸ƒçš„å½¢å¼ï¼Œå†é‡‡ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°è®¡ç®—lossã€‚
å†å›é¡¾PyTorchçš„CrossEntropyLoss()ï¼Œå®˜æ–¹æ–‡æ¡£ä¸­æåˆ°æ—¶å°†nn.LogSoftmax()å’Œ nn.NLLLoss()è¿›è¡Œäº†ç»“åˆï¼Œnn.LogSoftmax() ç›¸å½“äºæ¿€æ´»å‡½æ•° ï¼Œ nn.NLLLoss()æ˜¯æŸå¤±å‡½æ•°ï¼Œå°†å…¶ç»“åˆï¼Œå®Œæ•´çš„æ˜¯å¦å¯ä»¥å«åšsoftmax+äº¤å‰ç†µæŸå¤±å‡½æ•°å‘¢ï¼Ÿ   
* è®¡ç®—å…¬å¼ï¼š   
![](../../imgs/api/04.png)   

* å‚æ•°ï¼š  
    * weight(Tensor)- ä¸ºæ¯ä¸ªç±»åˆ«çš„lossè®¾ç½®æƒå€¼ï¼Œå¸¸ç”¨äºç±»åˆ«ä¸å‡è¡¡é—®é¢˜ã€‚weightå¿…é¡»æ˜¯floatç±»å‹çš„tensorï¼Œå…¶é•¿åº¦è¦äºç±»åˆ«Cä¸€è‡´ï¼Œå³æ¯ä¸€ä¸ªç±»åˆ«éƒ½è¦è®¾ç½®æœ‰weightã€‚å¸¦weightçš„è®¡ç®—å…¬å¼ï¼š
    * size_average(bool)- å½“reduce=Trueæ—¶æœ‰æ•ˆã€‚ä¸ºTrueæ—¶ï¼Œè¿”å›çš„lossä¸ºå¹³å‡å€¼ï¼›ä¸ºFalseæ—¶ï¼Œè¿”å›çš„å„æ ·æœ¬çš„lossä¹‹å’Œã€‚
    * reduce(bool)- è¿”å›å€¼æ˜¯å¦ä¸ºæ ‡é‡ï¼Œé»˜è®¤ä¸ºTrue
    * ignore_index(int)- å¿½ç•¥æŸä¸€ç±»åˆ«ï¼Œä¸è®¡ç®—å…¶lossï¼Œå…¶lossä¼šä¸º0ï¼Œå¹¶ä¸”ï¼Œåœ¨é‡‡ç”¨size_averageæ—¶ï¼Œä¸ä¼šè®¡ç®—é‚£ä¸€ç±»çš„lossï¼Œé™¤çš„æ—¶å€™çš„åˆ†æ¯ä¹Ÿä¸ä¼šç»Ÿè®¡é‚£ä¸€ç±»çš„æ ·æœ¬ã€‚
* å®ä¾‹ï¼š   
[link](https://github.com/TingsongYu/PyTorch_Tutorial/blob/master/Code/3_optimizer/3_1_lossFunction/3_CrossEntropyLoss.py)   
* è¡¥å……ï¼š   
outputä¸ä»…å¯ä»¥æ˜¯å‘é‡ï¼Œè¿˜å¯ä»¥æ˜¯å›¾ç‰‡ï¼Œå³å¯¹å›¾åƒè¿›è¡Œåƒç´ ç‚¹çš„åˆ†ç±»ï¼Œè¿™ä¸ªä¾‹å­å¯ä»¥ä»NLLLoss()ä¸­çœ‹åˆ°ï¼Œè¿™åœ¨å›¾åƒåˆ†å‰²å½“ä¸­å¾ˆæœ‰ç”¨ã€‚

## å››ã€CTCLoss
CLASStorch.nn.CTCLoss(blank=0, reduction='mean', zero_infinity=False)
## äº”ã€NLLLoss
CLASStorch.nn.NLLLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')
## å…­ã€PoissonNLLLoss
CLASStorch.nn.PoissonNLLLoss(log_input=True, full=False, size_average=None, eps=1e-08, reduce=None, reduction='mean')
## ä¸ƒã€KLDivLoss
CLASStorch.nn.KLDivLoss(size_average=None, reduce=None, reduction='mean')
## å…«ã€BCELoss
CLASStorch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')
## ä¹ã€BCEWithLogitsLoss
CLASStorch.nn.BCEWithLogitsLoss(weight=None, size_average=None, reduce=None, reduction='mean', pos_weight=None)
## åã€MarginRankingLoss
CLASStorch.nn.MarginRankingLoss(margin=0.0, size_average=None, reduce=None, reduction='mean')
## åä¸€ã€HingeEmbeddingLoss
CLASStorch.nn.HingeEmbeddingLoss(margin=1.0, size_average=None, reduce=None, reduction='mean')
## åäºŒã€MultiLabelMarginLoss
CLASStorch.nn.MultiLabelMarginLoss(size_average=None, reduce=None, reduction='mean')
## åä¸‰ã€SmoothL1Loss
CLASStorch.nn.SmoothL1Loss(size_average=None, reduce=None, reduction='mean')
## åå››ã€SoftMarginLoss
CLASStorch.nn.SoftMarginLoss(size_average=None, reduce=None, reduction='mean')
## åäº”ã€MultiLabelSoftMarginLoss
CLASStorch.nn.MultiLabelSoftMarginLoss(weight=None, size_average=None, reduce=None, reduction='mean')
## åå…­ã€CosineEmbeddingLoss
CLASStorch.nn.CosineEmbeddingLoss(margin=0.0, size_average=None, reduce=None, reduction='mean')
## åä¸ƒã€MultiMarginLoss
CLASStorch.nn.MultiMarginLoss(p=1, margin=1.0, weight=None, size_average=None, reduce=None, reduction='mean')
## åå…«ã€TripletMarginLoss
CLASStorch.nn.TripletMarginLoss(margin=1.0, p=2.0, eps=1e-06, swap=False, size_average=None, reduce=None, reduction='mean')