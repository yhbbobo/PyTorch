# torch.utils.data
* [å®˜æ–¹API](https://pytorch.org/docs/stable/data.html#module-torch.utils.data)    
* [ä¸­æ–‡API](https://pytorch.apachecn.org/docs/1.2/data.html)   

![](../../res/torchAPI/torch_utils_data.png) 

## å®ä¾‹-1ï¼ˆå®˜æ–¹å®ä¾‹ï¼‰
`../../code/load_pre.ipynb`-[ğŸ”—](../../code/load_pre.ipynb)   

è§£å†³ä»»ä½•æœºå™¨å­¦ä¹ é—®é¢˜çš„è®¸å¤šåŠªåŠ›éƒ½ç”¨äºå‡†å¤‡æ•°æ®ã€‚PyTorchæä¾›äº†è®¸å¤šå·¥å…·æ¥ç®€åŒ–å’Œå¸Œæœ›æ•°æ®åŠ è½½ï¼Œä½¿æ‚¨çš„ä»£ç æ›´å…·å¯è¯»æ€§ã€‚æˆ‘ä»¬å°†äº†è§£å¦‚ä½•ä»éå¹³å‡¡çš„æ•°æ®é›†åŠ è½½å’Œé¢„å¤„ç†/æ‰©å……æ•°æ®ã€‚  
è¦è¿è¡Œæœ¬æ•™ç¨‹ï¼Œè¯·ç¡®ä¿å®‰è£…äº†ä»¥ä¸‹è½¯ä»¶åŒ…ï¼š  
* scikit-imageï¼šå¯¹äºå›¾åƒioå’Œå˜æ¢
* pandasï¼šæ›´å®¹æ˜“è¿›è¡Œcsvè§£æ
## å®ä¾‹-2ï¼ˆAPIç¿»è¯‘ï¼‰
å®˜ç½‘API[ç¿»è¯‘](./torch_utils_data_1.md)
## å®ä¾‹-3(torchvisionåŒ…)
torchvision.dataset
* torchvision.datasets
    * MNIST
    * Fashion-MNIST
    * KMNIST
    * EMNIST
    * QMNIST
    * FakeData
    * COCO
    * LSUN
    * ImageFolder
    * DatasetFolder
    * ImageNet
    * CIFAR
    * STL10
    * SVHN
    * PhotoTour
    * SBU
    * Flickr
    * VOC
    * Cityscapes
    * SBD
    * USPS
    * Kinetics-400
    * HMDB51
    * UCF101
* torchvision.io
    * Video
* torchvision.models
    * Classification
    * Semantic Segmentation
    * Object Detection, Instance     Segmentation and Person Keypoint Detection
    * Video classification
* torchvision.ops
* torchvision.transforms
    * Transforms on PIL Image
    * Transforms on torch.*Tensor
    * Conversion Transforms
    * Generic Transforms
    * Functional Transforms
* torchvision.utils
## å®ä¾‹-4(ImageFolder)
ImageFolderä½¿ç”¨
ImageFolderå‡è®¾æ‰€æœ‰çš„æ–‡ä»¶æŒ‰æ–‡ä»¶å¤¹ä¿å­˜å¥½ï¼Œæ¯ä¸ªæ–‡ä»¶å¤¹ä¸‹é¢å­˜è´®åŒä¸€ç±»åˆ«çš„å›¾ç‰‡ï¼Œæ–‡ä»¶å¤¹çš„åå­—ä¸ºåˆ†ç±»çš„åå­—ã€‚
```
ImageFolder(root,transform=None,target_transform=None,loader=default_loader)
```
* root : åœ¨æŒ‡å®šçš„rootè·¯å¾„ä¸‹é¢å¯»æ‰¾å›¾ç‰‡ 
* transform: å¯¹PIL Imageè¿›è¡Œè½¬æ¢æ“ä½œ,transform è¾“å…¥æ˜¯loaderè¯»å–å›¾ç‰‡è¿”å›çš„å¯¹è±¡ 
* target_transform :å¯¹labelè¿›è¡Œå˜æ¢ 
* loader: æŒ‡å®šåŠ è½½å›¾ç‰‡çš„å‡½æ•°ï¼Œé»˜è®¤æ“ä½œæ˜¯è¯»å–PIL imageå¯¹è±¡

### ä¾‹å­
```
from torchvision.datasets import ImageFolder

dataset=ImageFolder('../data/dogcat/')

#å¯¹åº”æ–‡ä»¶å¤¹çš„label
print(dataset.class_to_idx)
```
è¾“å‡ºï¼š
```
{'cat': 0, 'dog': 1}
```
   
```
#æ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„å’Œå¯¹åº”çš„label
print(dataset.imgs)
```
è¾“å‡ºï¼š
``` 
[(â€˜data/dogcat/cat/cat.12484.jpgâ€™, 0), 
(â€˜data/dogcat/cat/cat.12485.jpgâ€™, 0), 
(â€˜data/dogcat/cat/cat.12486.jpgâ€™, 0), 
(â€˜data/dogcat/cat/cat.12487.jpgâ€™, 0), 
(â€˜data/dogcat/dog/dog.12496.jpgâ€™, 1), 
(â€˜data/dogcat/dog/dog.12497.jpgâ€™, 1), 
(â€˜data/dogcat/dog/dog.12498.jpgâ€™, 1), 
(â€˜data/dogcat/dog/dog.12499.jpgâ€™, 1)]
```
   
```
#æ²¡æœ‰ä»»ä½•è½¬å˜ï¼Œæ‰€æœ‰è¿”å›çš„è¿˜æ˜¯PIL Imageå¯¹è±¡
print(dataset[0][1]) #ç¬¬äºŒç»´åº¦ä¸º1 ï¼Œè¡¨ç¤ºlabel
print(dataset[0][0]) #ç¬¬äºŒç»´åº¦ä¸º0ï¼Œè¡¨ç¤ºå›¾ç‰‡æ•°æ®
```
è¾“å‡º:
``` 
0 
< PIL.Image.Image image mode=RGB size=497x500 at 0x7F25F3D31E10>
```

å®Œæ•´ä»£ç ï¼š
```python
# æ•°æ®å¤„ç†
import os
import torch
from torch.utils import data
from PIL import Image
import numpy as np
from torchvision import transforms

transform = transforms.Compose([
    transforms.Resize(224),  # ç¼©æ”¾å›¾ç‰‡ï¼Œä¿æŒé•¿å®½æ¯”ä¸å˜ï¼Œæœ€çŸ­è¾¹çš„é•¿ä¸º224åƒç´ ,
    transforms.CenterCrop(224),  # ä»ä¸­é—´åˆ‡å‡º 224*224çš„å›¾ç‰‡
    transforms.ToTensor(),  # å°†å›¾ç‰‡è½¬æ¢ä¸ºTensor,å½’ä¸€åŒ–è‡³[0,1]
    transforms.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5])  # æ ‡å‡†åŒ–è‡³[-1,1]
])


# å®šä¹‰è‡ªå·±çš„æ•°æ®é›†åˆ
class DogCat(data.Dataset):

    def __init__(self,root,transform):
        # æ‰€æœ‰å›¾ç‰‡çš„ç»å¯¹è·¯å¾„
        imgs = os.listdir(root)

        self.imgs = [os.path.join(root, k) for k in imgs]
        self.transforms = transform

    def __getitem__(self, index):
        img_path = self.imgs[index]
        # dog-> 1 cat ->0
        label = 1 if 'dog' in img_path.split('/')[-1] else 0
        pil_img = Image.open(img_path)
        if self.transforms:
            data = self.transforms(pil_img)
        else:
            pil_img = np.asarray(pil_img)
            data = torch.from_numpy(pil_img)
        return data, label

    def __len__(self):
        return len(self.imgs)


dataSet = DogCat('../data/dataset', transform=transform)

print(dataSet[0])
```
## å®ä¾‹-5(fn_collect)
fn_collect
```python
# æ•°æ®å¤„ç†
import os
import torch
from torch.utils import data
from PIL import Image
import numpy as np
from torchvision import transforms

transform = transforms.Compose([
    transforms.Resize(224),  # ç¼©æ”¾å›¾ç‰‡ï¼Œä¿æŒé•¿å®½æ¯”ä¸å˜ï¼Œæœ€çŸ­è¾¹çš„é•¿ä¸º224åƒç´ ,
    transforms.CenterCrop(224),  # ä»ä¸­é—´åˆ‡å‡º 224*224çš„å›¾ç‰‡
    transforms.ToTensor(),  # å°†å›¾ç‰‡è½¬æ¢ä¸ºTensor,å½’ä¸€åŒ–è‡³[0,1]
    transforms.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5])  # æ ‡å‡†åŒ–è‡³[-1,1]
])


# å®šä¹‰è‡ªå·±çš„æ•°æ®é›†åˆ
class DogCat(data.Dataset):

    def __init__(self,root,transform):
        # æ‰€æœ‰å›¾ç‰‡çš„ç»å¯¹è·¯å¾„
        imgs = os.listdir(root)

        self.imgs = [os.path.join(root, k) for k in imgs]
        self.transforms = transform

    def __getitem__(self, index):
        img_path = self.imgs[index]
        # dog-> 1 cat ->0
        label = 1 if 'dog' in img_path.split('/')[-1] else 0
        pil_img = Image.open(img_path)
        if self.transforms:
            data = self.transforms(pil_img)
        else:
            pil_img = np.asarray(pil_img)
            data = torch.from_numpy(pil_img)
        return data, label

    def __len__(self):
        return len(self.imgs)


dataSet = DogCat('../data/dataset', transform=transform)

print(dataSet[0])
```